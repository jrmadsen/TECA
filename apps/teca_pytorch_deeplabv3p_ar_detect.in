#!/usr/bin/env python@TECA_PYTHON_VERSION@
from teca import *
import sys
import argparse
import numpy as np
try:
    from mpi4py import MPI
    comm = MPI.COMM_WORLD
    rank = comm.Get_rank()
except:
    rank = 0


def get_padding_params(lat, lon):
    target_shape = 128 * np.ceil(lat/128.0)
    target_shape_diff = target_shape - lat
    padding_amount_lat = (int(np.ceil(target_shape_diff / 2.0)), int(np.floor(target_shape_diff / 2.0)))

    target_shape = 64 * np.ceil(lon/64.0)
    target_shape_diff = target_shape - lon
    padding_amount_lon = (int(np.ceil(target_shape_diff / 2.0)), int(np.floor(target_shape_diff / 2.0)))

    return padding_amount_lat, padding_amount_lon

def main():
    # parse the command line
    parser = argparse.ArgumentParser()
    parser.add_argument('--input_file', type=str, required=False,
        help='file path to the simulation to search for atmospheric rivers')

    parser.add_argument('--input_regex', type=str, required=False,
        help='regex matching simulation files to search for atmospheric rivers')

    parser.add_argument('--output_file', type=str, required=False,
        default='pytorch_deeplabv3p_ar_detect_\%t\%.nc',
        help='file pattern for output netcdf files (\%t\% is the time index)')

    parser.add_argument('--ivt', type=str, default='IVT',
        help='name of variable with integrated vapor transport (IVT)')

    parser.add_argument('--pytorch_deeplab_model', type=str, required=False,
        help='the pretrained deeplabv3plus model file')

    parser.add_argument('--pytorch_resnet_model', type=str, required=False,
        help='the pretrained resnet model file')

    parser.add_argument('--t_axis_variable', type=str, required=False,
        help='time dimension name')

    parser.add_argument('--t_calendar', type=str, required=False,
        help='time calendar')

    parser.add_argument('--t_units', type=str, required=False,
        help='time unit')

    parser.add_argument('--filename_time_template', type=str, required=False,
        help='filename time template')

    parser.add_argument('--compression_level', type=int, required=False,
        help='the compression level used for each variable')

    parser.add_argument('--date_format', type=str, required=False,
        help='the format for the date to write in the filename')

    parser.add_argument('--first_step', type=int, required=False,
        help='first time step to process')

    parser.add_argument('--last_step', type=int, required=False,
        help='last time step to process')

    parser.add_argument('--steps_per_file', type=int, required=False,
        help='number of time steps per output file')

    parser.add_argument('--start_date', type=str, required=False,
        help='first time to proces in YYYY-MM-DD hh:mm:ss format')

    parser.add_argument('--end_date', type=str, required=False,
        help='end time to proces in YYYY-MM-DD hh:mm:ss format')

    args = parser.parse_args()

    if not args.input_file and not args.input_regex:
        if rank == 0:
            raise parser.error(
                    "missing file name or regex for simulation reader. "
                    "See --help for a list of command line options.")

    cf_reader = teca_cf_reader.New()

    mesh_padder = teca_mesh_padding.New()
    mesh_padder.set_input_connection(cf_reader.get_output_port())

    deeplabv3p_ar_detect = teca_deeplabv3p_ar_detect.New()
    deeplabv3p_ar_detect.set_input_connection(mesh_padder.get_output_port())

    teca_exec = teca_index_executive.New()

    cf_writer = teca_cf_writer.New()
    cf_writer.set_input_connection(deeplabv3p_ar_detect.get_output_port())
    cf_writer.set_thread_pool_size(1)

    if args.input_file:
        cf_reader.append_file_name(
            args.input_file)

    if args.input_regex:
        cf_reader.set_files_regex(
            args.input_regex)

    if args.output_file:
        cf_writer.set_file_name(
            args.output_file)

    if args.ivt:
        deeplabv3p_ar_detect.set_variable_name(
            args.ivt)

    if args.pytorch_deeplab_model and args.pytorch_resnet_model:
        deeplabv3p_ar_detect.build_model(
            args.pytorch_deeplab_model,
            args.pytorch_resnet_model)
    else:
        deeplabv3p_ar_detect.build_model()

    if args.t_axis_variable is not None:
        cf_reader.set_t_axis_variable(
            args.t_axis_variable)

    if args.t_calendar:
        cf_reader.set_t_calendar(
            args.t_calendar)

    if args.t_units:
        cf_reader.set_t_units(
            args.t_units)

    if args.filename_time_template:
        cf_reader.set_filename_time_template(
            args.filename_time_template)

    if args.compression_level:
        cf_writer.set_compression_level(
            args.compression_level)

    if args.date_format:
        cf_writer.set_date_format(
            args.date_format)

    if args.first_step:
        cf_writer.set_first_step(
            args.first_step)

    if args.last_step:
        cf_writer.set_last_step(
            args.last_step)

    if args.steps_per_file:
        cf_writer.set_steps_per_file(
            args.steps_per_file)

    # some minimal check for missing options
    if cf_reader.get_number_of_file_names() == 0 and \
        not cf_reader.get_files_regex():
        if rank == 0:
            raise ValueError(
                    "missing file name or regex for simulation reader. "
                    "See --help for a list of command line options.")
    
    if not cf_writer.get_file_name():
        if rank == 0:
            raise ValueError(
                    "missing file name pattern for netcdf writer. "
                    "See --help for a list of command line options.")

    # run the reporting phase of the pipeline
    md = cf_reader.update_metadata()

    try:
        atrs = md["attributes"]
    except:
        raise KeyError("metadata missing attributes")

    try:
        lat = atrs['lat']['dims']
        lon = atrs['lon']['dims']
    except:
        raise KeyError(
                "failed to determine the geographic coordinates")

    # Setting the padding dimensions
    padding_amount_lat, padding_amount_lon = get_padding_params(lat, lon)
    mesh_padder.set_py_low(padding_amount_lat[0])
    mesh_padder.set_py_high(padding_amount_lat[1])
    mesh_padder.set_px_low(padding_amount_lon[0])
    mesh_padder.set_px_high(padding_amount_lon[1])

    if args.start_date or args.end_date:
        try:
            time_atts = atrs["time"]
            calendar = time_atts["calendar"]
            units = time_atts["units"]
        except:
            raise ValueError(
                    "failed to determine the calendaring parameters")

        try:
            coords = md["coordinates"]
            time = coords["t"]
        except:
            raise ValueError("failed to determine time coordinate")

        # convert date string to step, start date
        if args.start_date:
            first_step = teca_coordinate.time_step_of(time, True, calendar,
                 units, args.start_date)
            if not first_step:
                raise ValueError(
                        "Failed to locate time step for start date \""
                        + args.start_date + "\"")
            teca_exec.set_start_index(first_step)

        # and end date
        if args.end_date:
            last_step = teca_coordinate.time_step_of(time, False, calendar,
                 units, args.end_date)
            if not last_step:
                raise ValueError(
                        "Failed to locate time step for end date \""
                        +  args.end_date + "\"")
            teca_exec.set_end_index(last_step)

    # run the pipeline
    cf_writer.set_executive(teca_exec)
    cf_writer.update()

if __name__ == '__main__':
    main()